# 使用随机森林 (Random Forest) 进行 LTV 预测分析

## 1. 分析目标

本分析旨在使用 **随机森林 (Random Forest)** 算法替换原有的线性回归模型，以提升对客户生命周期价值 (LTV) 的预测效果。随机森林作为一种集成学习方法，能够有效处理特征间的非线性关系和交互，通常比单一的线性模型具有更强的预测能力。

## 2. 预期优势

1.  **更强的模型表达能力**：随机森林由多个决策树组成，能够拟合比线性回归更复杂的函数关系，捕捉数据中的非线性模式。
2.  **处理特征交互**：模型可以自动学习特征之间的交互作用，例如 "高消费频率 (F) 且高客单价 (M)" 的用户可能具有远超两者单独影响的 LTV。
3.  **鲁棒性**：通过集成多棵树的结果，随机森林对噪声和异常值的鲁棒性通常优于单个决策树或线性模型。
4.  **特征重要性评估**：随机森林可以提供各特征的重要性评分，帮助我们理解哪些 RFM 特征（或后续添加的衍生特征）对预测 LTV 最为关键。

## 3. 实施步骤

1.  **数据准备**：复用 `回归算法预测LTV.ipynb` 中已经处理好的特征集 `X` 和标签集 `y`。
2.  **模型训练**：
    *   导入 `sklearn.ensemble.RandomForestRegressor`。
    *   初始化 `RandomForestRegressor` 模型实例。可以先使用默认参数进行初步测试。
    *   使用训练集数据 (`X_train`, `y_train`) 对模型进行训练 (`.fit()`)。
3.  **模型预测**：
    *   使用训练好的模型对训练集 (`X_train`) 和测试集 (`X_test`) 进行预测，得到 `y_train_preds_rf` 和 `y_test_preds_rf`。
4.  **模型评估**：
    *   使用 `sklearn.metrics.r2_score` 计算随机森林模型在训练集和测试集上的 R² 分数。
    *   将随机森林的 R² 分数与原线性回归模型的分数进行比较。
    *   绘制测试集的 `实际值 vs. 预测值` 散点图，直观比较预测效果。
5.  **特征重要性分析**：
    *   获取训练完成的 `RandomForestRegressor` 模型的 `.feature_importances_` 属性。
    *   将特征重要性与特征名称 (`X.columns`) 结合，创建一个 Pandas Series 并进行排序。
    *   打印或可视化（如条形图）排序后的特征重要性，以识别对 LTV 预测贡献最大的特征。

## 4. 预期结果

通过以上步骤，我们预期能够：
*   获得一个使用随机森林训练的 LTV 预测模型。
*   得到该模型在训练集和测试集上的 R² 分数。
*   通过与线性回归模型的对比，量化随机森林带来的性能提升。
*   了解在当前特征集下，R值、F值、M值各自对预测结果的相对重要性。

这个初步的随机森林应用将作为模型改进的第一步。后续可根据此结果，结合 `model_improvement_plan.md` 中的建议，进一步进行特征工程和模型超参数调优。